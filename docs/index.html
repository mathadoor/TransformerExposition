<!--
  Copyright 2018 The Distill Template Authors

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!doctype html>

<head>
  <script src="template.v2.js"></script>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf8">
</head>

<body>
  <distill-header></distill-header>
  <d-front-matter>
    <script id='distill-front-matter' type="text/json">{
    "title": "Transformer Explainer",
    "description": "The website serves to explain the architectural components of the transformers through interactive visualization.",
    "published": "July 31, 2023",
    "authors": [
      {
        "author":"Harpreet Matharoo",
        "authorURL":"https://mathadoor.github.io/",
        "affiliations": [{"name": "Georgia Institute of Technology"}]
      }
    ],
    "katex": {
      "delimiters": [
        {"left": "$$", "right": "$$", "display": false}
      ]
    }
  }</script>
  </d-front-matter>

  <d-title>
<!--Sub title of the website-->
    <p>Learn how transformer architecture works for language translation.</p>
<!--    <d-cite key="mercier2011humans"></d-cite>-->
  </d-title>
  <div id='arch'></div>
  <script src="bundle.js"></script>
<!--  <d-byline></d-byline>-->
  <d-article>
<!--    <a class="marker" href="#section-1" id="section-1"><span>1</span></a>-->
    <h2>Introduction</h2>
    <p>
        Recent years have seen significant advancements in artificial intelligence, which birthed systems capable of performing
      similar to humans in language related tasks<d-cite bibtex-key="zhao2023survey"></d-cite>. Such advancements were made
      possible due to the introduction of the transformer architecture. Before transformer, the language modeling tasks were
      performed using different variants of recurrent neural networks(RNNs). However, the inherent structure of RNNs placed
      limitations on its expressivity and training speed<d-cite bibtex-key="pascanu2013difficulty"></d-cite>. As such, these
      models failed to learn meaningful concepts for more complex tasks such as language translations. The transformer
      architecture lifted these limitations and enabled training models of unprecedented scale and abilities<d-cite bibtex-key="wei2022emergent"></d-cite>.
      Consequently, the research output has increased exponentially.
    </p>

    <p>
      While this exponential increment in the research output is attractive, maintaining this pace of research becomes challenging
      as proportionally equal amount of research debt is added. Such debt lengthens the lead time to meaningful participation
      by the aspiring researchers and stilfes further progress<d-cite bibtex-key="olah2017research"></d-cite>. Interactive
      visualization has shown great promise in shortening this lead time and facilitating a deeper understanding of the
      subject<d-cite bibtex-key="hohman2020communicating"></d-cite>. To this end, this article exposes the inner workings
      of the transformer architecture for language translation via an interactive visualization. The seminal encoder-decoder
      architecture<d-cite bibtex-key="vaswani2017attention"></d-cite> is chosen as it is often the starting point from
      which the newcomers to the language modeling began. The rest of the article details different parts of the visualization.
    </p>
    <h2>Using the Visualization</h2>
    <p>
      As noted earlier, the exposition in this article refers to the encoder-decoder variant of the transformer architecture.
      The technical contents of the visualization assumes familiarity with deep learning concepts. An unfamiliar reader is
      urged to review the material listed in the <a href="#suggPreq">suggested pre-requisites</a> section.
      Now, there are three types of visual components in the visualization. Their description are as follows:
      <ol>
    <li><b>Input Selector</b>: The component is located at the top-corner of the architecture. The user can select a component
    from the drop-down menu or enter a sentence of their own interest.
      <d-figure id="overall-arch">
        <figure style="width:50%; position:relative; left: 25%">
          <img src="./assets/input_gif.gif" alt="Trulli" style="width:100%">
          <figcaption style="text-align: center; margin-left: 10%; width: 80%;">Fig. 1 - Input Selection.</figcaption>
        </figure>
      </d-figure>
    </li>
    <li><b>Explorable</b>: The explorable components are the ones that can be clicked on to reveal their internal structure.
      The subcomponents can be further clicked on to reveal a description of its underlying operations. In total, there are 9
      explorable components - input and output embeddings, encoders, decoders, and output layer.
      <d-figure id="overall-arch">
        <figure style="width:80%; position:relative; left: 10%">
          <img src="./assets/explorable.gif" alt="Trulli" style="width:100%">
          <figcaption style="text-align: center; margin-left: 10%; width: 80%;"> Fig. 2 - Interaction with input embedding component.</figcaption>
        </figure>
      </d-figure>
    </li>
    <li><b>Controller</b>: The controller is the unique component that lets the user step through the translation process. Note the target sentence
      is one token behind as it is used in conjunction with the encoding of the source sentence, to predict the next token in the sequence.
      <d-figure id="overall-arch">
        <figure style="width:120%; position:relative; left: -10%">
          <img src="./assets/controller_gif.gif" alt="Trulli" style="width:100%">
          <figcaption style="text-align: center; margin-left: 10%; width: 80%;"> Fig. 3 - Stepping through the translation using the controller..</figcaption>
        </figure>
      </d-figure>
    </li>

    </li>
  </ol>
    </p>

    <h2 id="suggPreq">Suggested Pre-requisites</h2>
    <ol>
      <li><b><a href="https://www.youtube.com/watch?v=i_LwzRVP7bg&t=29s&ab_channel=freeCodeCamp.org" target="_blank">Machine Learning for everybody</a> by Freecodecamp.org</b></li>
      <li><b><a href="http://playground.tensorflow.org/" target="_blank">Tensorflow Playground</a> a sandbox environment to play with neural networks.</b></li>
      <li><b><a href="https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi" target="_blank">Neural Networks by 3Blue1Brown</a> for an intuitive explanation of how neural networks work.</b></li>
      <li><b><a href="https://www.coursera.org/specializations/deep-learning" target="_blank">Deep Learning Specialization by Deeplearning.ai</a> for learning to implement neural networks and train them.</b></li>
      <li><b><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank">The Unreasonable Effectiveness of Recurrent Neural Networks by Andrej Karpathy</a> for developing an intuitive understanding of how RNNs work.</b></li>
      <li><b><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank">Understanding LSTM Networks by Chris Olah</a> for understanding how LSTM networks work.</b></li>
      <li><b><a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank">Visualizing A Neural Machine Translation Model by Jay Alammar</a> for understanding how attention mechanism helps with the aligning neural machine translation.</b></li>
      <li><b><a href="https://jalammar.github.io/illustrated-transformer/" target="_blank">The Illustrated Transformer by Jay Alammar</a> supplemental material for developing an intuitive understanding of the transformer architecture.</b></li>

    </ol>
<!--    As noted earlier, the article presents the encoder-decoder architecture.-->
<!--    <p>Describe the overall architecture here including how encoder-decoder works.</p>-->
<!--    <h2>Architectural Components</h2>-->
<!--    <p>Here describe the specifics of the components at level 2</p>-->
<!--    <h3>Input</h3>-->
<!--    <p>Describe the input embeddings here</p>-->
<!--    <h3>Encoder/Decoder Components</h3>-->
<!--    <p>Describe the components of the encoder-decoder</p>-->
<!--    <h4>Multi-headed Self-Attention</h4>-->
<!--    <h4>Position Wise MLP layers</h4>-->
<!--    <h3>Output</h3>-->
<!--    <p>Describe how the output is generated</p>-->

<!--    <p>This is the first paragraph of the article. Test a long&thinsp;&mdash;&thinsp;dash &#45;&#45; here it is.</p>-->
<!--    <p>Test for owner's possessive. Test for "quoting a passage." And another sentence. Or two. Some flopping fins; for-->
<!--      diving.</p>-->
<!--    <aside>Some text in an aside, margin notes, etc...</aside>-->
<!--    <p>Here's a test of an inline equation <d-math>c = a^2 + b^2</d-math>. Also with configurable katex standards just-->
<!--      using inline '$' signs: $$x^2$$ And then there's a block equation:</p>-->
<!--    <d-math block>-->
<!--      c = \pm \sqrt{ \sum_{i=0}^{n}{a^{222} + b^2}}-->
<!--    </d-math>-->
<!--    <p>Math can also be quite involved:</p>-->
<!--    <d-math block>-->
<!--      \frac{1}{\Bigl(\sqrt{\phi \sqrt{5}}-\phi\Bigr) e^{\frac25 \pi}} = 1+\frac{e^{-2\pi}} {1+\frac{e^{-4\pi}}-->
<!--      {1+\frac{e^{-6\pi}} {1+\frac{e^{-8\pi}} {1+\cdots} } } }-->
<!--    </d-math>-->
<!--    <a class="marker" href="#section-1.1" id="section-1.1"><span>1.1</span></a>-->
<!--    <h3>Citations</h3>-->
<!--    <p>-->
<!--      <d-slider style="width: 200px;"></d-slider>-->
<!--    </p>-->
<!--    <p>We can<d-cite bibtex-key="mercier2011humans"></d-cite> also cite <d-cite-->
<!--        key="gregor2015draw,mercier2011humans,openai2018charter"></d-cite> external publications. <d-cite-->
<!--        key="dong2014image,dumoulin2016guide,mordvintsev2015inceptionism"></d-cite>. We should also be testing footnotes-->
<!--      <d-footnote>This will become a hoverable footnote. This will become a hoverable footnote. This will become a-->
<!--        hoverable footnote. This will become a hoverable footnote. This will become a hoverable footnote. This will-->
<!--        become a hoverable footnote. This will become a hoverable footnote. This will become a hoverable footnote.-->
<!--      </d-footnote>. There are multiple footnotes, and they appear in the appendix<d-footnote>Given I have coded them-->
<!--        right. Also, here's math in a footnote: <d-math>c = \sum_0^i{x}</d-math>. Also, a citation. Box-ception<d-cite-->
<!--          key='gregor2015draw'></d-cite>!</d-footnote> as well.</p>-->
<!--    <a class="marker" href="#section-2" id="section-2"><span>2</span></a>-->
<!--    <h2>Displaying code snippets</h2>-->
<!--    <p>Some inline javascript:<d-code language="javascript">var x = 25;</d-code>. And here's a javascript code block.-->
<!--    </p>-->
<!--    <d-code block language="javascript">-->
<!--      var x = 25;-->
<!--      function(x){-->
<!--      return x * x;-->
<!--      }-->
<!--    </d-code>-->
<!--    <p>We also support python.</p>-->
<!--    <d-code block language="python">-->
<!--      # Python 3: Fibonacci series up to n-->
<!--      def fib(n):-->
<!--        a, b = 0, 1-->
<!--      while a < n: print(a, end=' ' ) a, b=b, a+b </d-code>-->
<!--        <p>And a table</p>-->
<!--        <table>-->
<!--          <thead>-->
<!--            <tr>-->
<!--              <th>First</th>-->
<!--              <th>Second</th>-->
<!--              <th>Third</th>-->
<!--            </tr>-->
<!--          </thead>-->
<!--          <tbody>-->
<!--            <tr>-->
<!--              <td>23</td>-->
<!--              <td>654</td>-->
<!--              <td>23</td>-->
<!--            </tr>-->
<!--            <tr>-->
<!--              <td>14</td>-->
<!--              <td>54</td>-->
<!--              <td>34</td>-->
<!--            </tr>-->
<!--            <tr>-->
<!--              <td>234</td>-->
<!--              <td>54</td>-->
<!--              <td>23</td>-->
<!--            </tr>-->
<!--          </tbody>-->
<!--        </table>-->
<!--        <d-figure id="last-figure"></d-figure>-->
<!--        <script>-->
<!--          const figure = document.querySelector("d-figure#last-figure");-->
<!--          const initTag = document.createElement("span");-->
<!--          initTag.textContent = "initialized!"-->
<!--          figure.appendChild(initTag);-->
<!--          figure.addEventListener("ready", function () {-->
<!--            const initTag = figure.querySelector("span");-->
<!--            initTag.textContent = "ready"-->
<!--          });-->
<!--          figure.addEventListener("onscreen", function () {-->
<!--            const initTag = figure.querySelector("span");-->
<!--            initTag.textContent = "onscreen"-->
<!--          });-->
<!--          figure.addEventListener("offscreen", function () {-->
<!--            const initTag = figure.querySelector("span");-->
<!--            initTag.textContent = "offscreen!"-->
<!--          });-->
<!--        </script>-->
<!--        <p>That's it for the example article!</p>-->

  </d-article>

  <d-appendix>

<!--    <p>Some text describing who did what.</p>-->
<!--    <h3>Reviewers</h3>-->
<!--    <p>Some text with links describing who reviewed the article.</p>-->

    <d-bibliography src="bibliography.bib"></d-bibliography>
  </d-appendix>


</body>
